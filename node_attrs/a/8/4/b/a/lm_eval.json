{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "conda_build": {
   "error_overlinking": true
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  }
 },
 "feedstock_name": "lm_eval",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "home": "https://github.com/EleutherAI/lm-evaluation-harness",
   "license": "MIT",
   "license_file": "LICENSE.md",
   "summary": "A framework for evaluating autoregressive language models"
  },
  "build": {
   "number": "0",
   "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
  },
  "extra": {
   "recipe-maintainers": [
    "mediocretech"
   ]
  },
  "package": {
   "name": "lm_eval",
   "version": "0.4.2"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub"
   ],
   "host": [
    "python",
    "pip"
   ],
   "run": [
    "python",
    "datasets >=2.0.0",
    "evaluate",
    "jsonlines",
    "numexpr",
    "openai >=0.6.4",
    "peft",
    "pybind11 >=2.6.2",
    "pycountry",
    "pytablewriter",
    "rouge-score >=0.0.4",
    "sacrebleu ==1.5.0",
    "scikit-learn >=0.24.1",
    "sqlitedict",
    "pytorch >=1.7",
    "tqdm-multiprocess",
    "transformers >=4.1",
    "zstandard",
    "more-itertools",
    "word2number"
   ]
  },
  "source": {
   "sha256": "ddc2a1ea7041cbadf45afd118ebdecd707b1f14446fad51df212d2bf3defb4d2",
   "url": "https://pypi.io/packages/source/l/lm_eval/lm_eval-0.4.2.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "lm_eval"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "datasets",
    "evaluate",
    "jsonlines",
    "more-itertools",
    "numexpr",
    "openai",
    "peft",
    "pybind11",
    "pycountry",
    "pytablewriter",
    "python",
    "pytorch",
    "rouge-score",
    "sacrebleu",
    "scikit-learn",
    "sqlitedict",
    "tqdm-multiprocess",
    "transformers",
    "word2number",
    "zstandard"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "home": "https://github.com/EleutherAI/lm-evaluation-harness",
   "license": "MIT",
   "license_file": "LICENSE.md",
   "summary": "A framework for evaluating autoregressive language models"
  },
  "build": {
   "number": "0",
   "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
  },
  "extra": {
   "recipe-maintainers": [
    "mediocretech"
   ]
  },
  "package": {
   "name": "lm_eval",
   "version": "0.4.2"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub"
   ],
   "host": [
    "python",
    "pip"
   ],
   "run": [
    "python",
    "datasets >=2.0.0",
    "evaluate",
    "jsonlines",
    "numexpr",
    "openai >=0.6.4",
    "peft",
    "pybind11 >=2.6.2",
    "pycountry",
    "pytablewriter",
    "rouge-score >=0.0.4",
    "sacrebleu ==1.5.0",
    "scikit-learn >=0.24.1",
    "sqlitedict",
    "pytorch >=1.7",
    "tqdm-multiprocess",
    "transformers >=4.1",
    "zstandard",
    "more-itertools",
    "word2number"
   ]
  },
  "source": {
   "sha256": "ddc2a1ea7041cbadf45afd118ebdecd707b1f14446fad51df212d2bf3defb4d2",
   "url": "https://pypi.io/packages/source/l/lm_eval/lm_eval-0.4.2.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "lm_eval"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "name": "lm_eval",
 "osx_64_meta_yaml": {
  "about": {
   "home": "https://github.com/EleutherAI/lm-evaluation-harness",
   "license": "MIT",
   "license_file": "LICENSE.md",
   "summary": "A framework for evaluating autoregressive language models"
  },
  "build": {
   "number": "0",
   "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
  },
  "extra": {
   "recipe-maintainers": [
    "mediocretech"
   ]
  },
  "package": {
   "name": "lm_eval",
   "version": "0.4.2"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub"
   ],
   "host": [
    "python",
    "pip"
   ],
   "run": [
    "python",
    "datasets >=2.0.0",
    "evaluate",
    "jsonlines",
    "numexpr",
    "openai >=0.6.4",
    "peft",
    "pybind11 >=2.6.2",
    "pycountry",
    "pytablewriter",
    "rouge-score >=0.0.4",
    "sacrebleu ==1.5.0",
    "scikit-learn >=0.24.1",
    "sqlitedict",
    "pytorch >=1.7",
    "tqdm-multiprocess",
    "transformers >=4.1",
    "zstandard",
    "more-itertools",
    "word2number"
   ]
  },
  "source": {
   "sha256": "ddc2a1ea7041cbadf45afd118ebdecd707b1f14446fad51df212d2bf3defb4d2",
   "url": "https://pypi.io/packages/source/l/lm_eval/lm_eval-0.4.2.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "lm_eval"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "osx_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "datasets",
    "evaluate",
    "jsonlines",
    "more-itertools",
    "numexpr",
    "openai",
    "peft",
    "pybind11",
    "pycountry",
    "pytablewriter",
    "python",
    "pytorch",
    "rouge-score",
    "sacrebleu",
    "scikit-learn",
    "sqlitedict",
    "tqdm-multiprocess",
    "transformers",
    "word2number",
    "zstandard"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "lm_eval"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64",
  "osx_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/lm_eval.json"
 },
 "raw_meta_yaml": "{% set name = \"lm_eval\" %}\n{% set version = \"0.4.2\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/lm_eval-{{ version }}.tar.gz\n  sha256: ddc2a1ea7041cbadf45afd118ebdecd707b1f14446fad51df212d2bf3defb4d2\n\nbuild:\n  skip: true  # [py2k]\n  skip: true  # [win]\n  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation\n  number: 0\n\nrequirements:\n  build:\n    - {{ compiler('cxx') }}\n  host:\n    - python\n    - pip\n  run:\n    - python\n    - datasets >=2.0.0\n    - evaluate\n    - jsonlines\n    - numexpr\n    - openai >=0.6.4\n    - peft\n    - pybind11 >=2.6.2\n    - pycountry\n    - pytablewriter\n    - rouge-score >=0.0.4\n    - sacrebleu ==1.5.0\n    - scikit-learn >=0.24.1\n    - sqlitedict\n    - pytorch >=1.7\n    - tqdm-multiprocess\n    - transformers >=4.1\n    - zstandard\n    - more-itertools\n    - word2number\n\ntest:\n  imports:\n    - lm_eval\n  commands:\n    - pip check\n  requires:\n    - pip\n\nabout:\n  home: https://github.com/EleutherAI/lm-evaluation-harness\n  summary: A framework for evaluating autoregressive language models\n  license: MIT\n  license_file: LICENSE.md\n\nextra:\n  recipe-maintainers:\n    - mediocretech\n",
 "req": {
  "__set__": true,
  "elements": [
   "cxx_compiler_stub",
   "datasets",
   "evaluate",
   "jsonlines",
   "more-itertools",
   "numexpr",
   "openai",
   "peft",
   "pip",
   "pybind11",
   "pycountry",
   "pytablewriter",
   "python",
   "pytorch",
   "rouge-score",
   "sacrebleu",
   "scikit-learn",
   "sqlitedict",
   "tqdm-multiprocess",
   "transformers",
   "word2number",
   "zstandard"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "datasets",
    "evaluate",
    "jsonlines",
    "more-itertools",
    "numexpr",
    "openai",
    "peft",
    "pybind11",
    "pycountry",
    "pytablewriter",
    "python",
    "pytorch",
    "rouge-score",
    "sacrebleu",
    "scikit-learn",
    "sqlitedict",
    "tqdm-multiprocess",
    "transformers",
    "word2number",
    "zstandard"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "datasets >=2.0.0",
    "evaluate",
    "jsonlines",
    "more-itertools",
    "numexpr",
    "openai >=0.6.4",
    "peft",
    "pybind11 >=2.6.2",
    "pycountry",
    "pytablewriter",
    "python",
    "pytorch >=1.7",
    "rouge-score >=0.0.4",
    "sacrebleu ==1.5.0",
    "scikit-learn >=0.24.1",
    "sqlitedict",
    "tqdm-multiprocess",
    "transformers >=4.1",
    "word2number",
    "zstandard"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/l/lm_eval/lm_eval-0.4.2.tar.gz",
 "version": "0.4.2",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/lm_eval.json"
 }
}