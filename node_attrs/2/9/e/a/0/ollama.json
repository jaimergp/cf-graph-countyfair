{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "build_platform": {
   "osx_arm64": "osx_64"
  },
  "conda_build": {
   "error_overlinking": true
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  },
  "test": "native_and_emulated"
 },
 "feedstock_name": "ollama",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": null,
   "number": "0",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.17 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./... || exit 1",
    "go install . || exit 1",
    "go-licenses save --save_path licenses ./... || exit 1"
   ],
   "string": "cuda120_h1234567_0"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.17"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "go_compiler_stub 1.21",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "cuda-cudart-dev  12.0",
    "libcublas-dev    12.0"
   ],
   "host": [
    "cuda-version     11.2",
    "cuda-version     11.8",
    "cuda-cudart-dev  12.0",
    "libcublas-dev    12.0"
   ],
   "run": [
    "cuda-version     11.2",
    "cuda-version     11.8"
   ]
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch",
     "0002-linux_all-disable-cuda.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda-cudart-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "libcublas-dev",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev",
    "cuda-version",
    "libcublas-dev"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cuda-version"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": null,
   "number": "0",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.17 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./... || exit 1",
    "go install . || exit 1",
    "go-licenses save --save_path licenses ./... || exit 1",
    "set GOFLAGS='-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.17 -X=github.com/jmorganca/ollama/server.mode=release'"
   ],
   "string": "cpu_h1234567_0"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.17"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "go_compiler_stub 1.21",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "cuda-cudart-dev  12.0",
    "libcublas-dev    12.0"
   ],
   "host": [
    "cuda-version     11.2",
    "cuda-version     11.8",
    "cuda-cudart-dev  12.0",
    "libcublas-dev    12.0"
   ],
   "run": [
    "cuda-version     11.2",
    "cuda-version     11.8"
   ]
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch",
     "0002-linux_all-disable-cuda.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "name": "ollama",
 "osx_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": [
    "cxx_compiler_stub"
   ],
   "number": "0",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.17 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./... || exit 1",
    "go install . || exit 1",
    "go-licenses save --save_path licenses ./... || exit 1"
   ],
   "string": "cpu_h1234567_0"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.17"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.21",
    "go-licenses",
    "git",
    "cmake",
    "make"
   ],
   "host": [],
   "run": []
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "osx_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": []
  },
  "run": {
   "__set__": true,
   "elements": []
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "osx_arm64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": [
    "cxx_compiler_stub"
   ],
   "number": "0",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.17 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./... || exit 1",
    "go install . || exit 1",
    "go-licenses save --save_path licenses ./... || exit 1"
   ],
   "string": "mps_h1234567_0"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.17"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.21",
    "go-licenses",
    "git",
    "cmake",
    "make"
   ],
   "host": [],
   "run": []
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "osx_arm64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": []
  },
  "run": {
   "__set__": true,
   "elements": []
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "ollama"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64",
  "osx_64",
  "osx_arm64",
  "win_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/ollama.json"
 },
 "raw_meta_yaml": "{% set name = \"ollama\" %}\n{% set goname = \"github.com/jmorganca/ollama\" %}\n{% set version = \"0.1.17\" %}\n# DO NOT AUTO MERGE WITHOUT VERIFYING THE GIT_REVISIONS OF ggml AND gguf\n{% set ggml_version = \"master-9e232f0\" %}\n{% set gguf_version = \"b1661\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  - url: https://{{ goname }}/archive/v{{ version }}.tar.gz\n    sha256: 5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2\n    folder: .\n    patches:\n      # Use the same build options from llama.cpp-feedstock\n      - 0001-remove-submodule.patch\n      - 0001-linux_all-do-not-copy-cuda.patch\n      - 0002-darwin_all-cmake-flags.patch\n      - 0002-linux_all-disable-cuda.patch  # [linux and cuda_compiler_version in (undefined, \"None\")]\n      # - 0002-win_all-use-ninja-paths.patch\n  - url: https://github.com/ggerganov/llama.cpp/archive/{{ ggml_version }}.tar.gz\n    folder: llm/llama.cpp/ggml\n    sha256: e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef \n    patches:\n      - ggml-metal-pick-device.patch\n  - url: https://github.com/ggerganov/llama.cpp/archive/{{ gguf_version }}.tar.gz\n    folder: llm/llama.cpp/gguf\n    sha256: 88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb\n    patches:\n      - gguf-metal-pick-device.patch\n\nbuild:\n  skip: true  # [win and cuda_compiler_version not in (\"None\", )]\n  number: 0\n  string: cuda{{ cuda_compiler_version | replace('.', '') }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n  string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [(osx and x86_64) or cuda_compiler_version == \"None\"]\n  string: mps_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [osx and arm64]\n  script:\n    - git config --system user.email \"conda-forge@numfocus.org\"\n    - git config --system user.name \"Conda Forge\"\n    - git config --global init.defaultBranch main\n    {% for framework in [\"ggml\", \"gguf\"] %}\n    - |\n      pushd llm{{ os.sep }}llama.cpp{{ os.sep }}{{ framework }}\n      git init\n      git add .\n      git commit -m \"conda-forge build\"\n      popd\n    {% endfor %}\n\n    - export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version={{ version }} -X=github.com/jmorganca/ollama/server.mode=release'\"  # [unix]\n    - set GOFLAGS='-ldflags=-X=github.com/jmorganca/ollama/version.Version={{ version }} -X=github.com/jmorganca/ollama/server.mode=release'       # [win]\n\n    - go generate ./... || exit 1\n    - go install . || exit 1                                                                                                  # [build_platform == target_platform]\n    # TODO: This is due to a bug in our go-lang patch \n    #       Error message is go install can't write to GOBIN when cross compiling\n    - unset CONDA_GO_COMPILER; GOPATH=$SRC_DIR/gopath go install .; mkdir -p $PREFIX/bin; cp gopath/bin/*/ollama $PREFIX/bin  # [build_platform != target_platform]\n    - go-licenses save --save_path licenses ./... || exit 1\n\n  ignore_run_exports_from:\n    # llama.cpp server is staticially linked on osx\n    - {{ compiler('cxx') }}  # [osx]\n\nrequirements:\n  build:\n    - {{ compiler('c') }}\n    - {{ compiler('cxx') }}\n    - {{ compiler('cuda') }}                    # [cuda_compiler_version not in (undefined, \"None\")]\n    - {{ compiler('go') }} 1.21\n    - go-licenses\n\n    - git\n    - cmake\n    - make\n\n    # Tool can't find cudart/cublas in the host-environment\n    - cuda-cudart-dev  {{ cuda_compiler_version }}  # [(cuda_compiler_version or \"\").startswith(\"12\")]\n    - libcublas-dev    {{ cuda_compiler_version }}  # [(cuda_compiler_version or \"\").startswith(\"12\")]\n  host:\n    # NOTE: Without cuda-version, we are installing cuda-toolkit 11.8 instead of 11.2!\n    - cuda-version     {{ cuda_compiler_version }}  # [cuda_compiler_version != \"None\" and not (cuda_compiler_version or \"\").startswith(\"12\")]\n    - cuda-cudart-dev  {{ cuda_compiler_version }}  # [(cuda_compiler_version or \"\").startswith(\"12\")]\n    - libcublas-dev    {{ cuda_compiler_version }}  # [(cuda_compiler_version or \"\").startswith(\"12\")]\n  run:\n    # NOTE: Without cuda-version, we are installing cuda-toolkit 11.8 instead of 11.2!\n    - cuda-version     {{ cuda_compiler_version }}  # [cuda_compiler_version != \"None\" and not (cuda_compiler_version or \"\").startswith(\"12\")]\n\ntest:\n  commands:\n    - ollama --version\n    - ollama --help\n\nabout:\n  home: https://ollama.ai\n  summary: Get up and running with Llama 2 and other large language models locally\n  license: MIT\n  license_family: MIT\n  license_file:\n    - LICENSE\n    - licenses/\n  dev_url: https://{{ goname }}\n\nextra:\n  recipe-maintainers:\n    - sodre\n",
 "req": {
  "__set__": true,
  "elements": [
   "c_compiler_stub",
   "cmake",
   "cuda-cudart-dev",
   "cuda-version",
   "cuda_compiler_stub",
   "cxx_compiler_stub",
   "git",
   "go-licenses",
   "go_compiler_stub",
   "libcublas-dev",
   "make"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda-cudart-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "libcublas-dev",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev",
    "cuda-version",
    "libcublas-dev"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cuda-version"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda-cudart-dev  12.0",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub 1.21",
    "libcublas-dev    12.0",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev  12.0",
    "cuda-version     11.2",
    "cuda-version     11.8",
    "libcublas-dev    12.0"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cuda-version     11.2",
    "cuda-version     11.8"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz",
 "version": "0.1.17",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/ollama.json"
 },
 "win_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": null,
   "number": "0",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "set GOFLAGS='-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.17 -X=github.com/jmorganca/ollama/server.mode=release'",
    "go generate ./... || exit 1",
    "go install . || exit 1",
    "go-licenses save --save_path licenses ./... || exit 1"
   ],
   "string": "cpu_h1234567_0"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.17"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.21",
    "go-licenses",
    "git",
    "cmake",
    "make"
   ],
   "host": [],
   "run": []
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch",
     "0002-darwin_all-cmake-flags.patch"
    ],
    "sha256": "5be6f90941a27cc61e9ad1a76dcfd2702f9d520758571ec4784a6f08de794ac2",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.17.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "patches": [
     "ggml-metal-pick-device.patch"
    ],
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "patches": [
     "gguf-metal-pick-device.patch"
    ],
    "sha256": "88b4befe7d44b18e9419a0604adad2c130bfea9af45100b8531822bb2e1184fb",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1661.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "win_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": []
  },
  "run": {
   "__set__": true,
   "elements": []
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 }
}